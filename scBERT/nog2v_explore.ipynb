{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import argparse\n",
    "import json\n",
    "import random\n",
    "import math\n",
    "import random\n",
    "from functools import reduce\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import sparse\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.optim import Adam\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "from torch.nn.modules.utils import consume_prefix_in_state_dict_if_present\n",
    "import torch.distributed as dist\n",
    "import torch.multiprocessing as mp\n",
    "from performer_pytorch import PerformerLM\n",
    "import scanpy as sc\n",
    "import anndata as ad\n",
    "from utils import *\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "from time import time\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=0\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=0\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = \"cuda:0\"\n",
    "CLASS=7\n",
    "PAD_TOKEN_ID = CLASS-1\n",
    "BATCH_SIZE=1\n",
    "MASK_PROB=0.15\n",
    "REPLACE_PROB=0.9\n",
    "RANDOM_TOKEN_PROB = 0\n",
    "MASK_TOKEN_ID = CLASS - 1\n",
    "MASK_IGNORE_TOKEN_IDS = [0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Control sources of randomness\n",
    "SEED=2021\n",
    "torch.manual_seed(SEED)\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SCDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        super().__init__()\n",
    "        self.data = data\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        #rand_start = random.randint(0, self.data.shape[0]-1)\n",
    "        full_seq = self.data[index].toarray()[0]\n",
    "        full_seq[full_seq > (CLASS - 2)] = CLASS - 2\n",
    "        full_seq = torch.from_numpy(full_seq).long() #long() converts to int64\n",
    "        full_seq = torch.cat((full_seq, torch.tensor([0]))).to(device)\n",
    "        return full_seq\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss(ignore_index = PAD_TOKEN_ID, reduction='mean').to(device)\n",
    "softmax = nn.Softmax(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# get the random prob matrix and True means smaller than prob threshold\n",
    "def prob_mask_like(t, prob):\n",
    "    return torch.zeros_like(t).float().uniform_(0, 1) < prob\n",
    "\n",
    "# get the mask matrix which cannot be masked\n",
    "def mask_with_tokens(t, token_ids):\n",
    "    init_no_mask = torch.full_like(t, False, dtype=torch.bool)\n",
    "    mask = reduce(lambda acc, el: acc | (t == el), token_ids, init_no_mask)\n",
    "    return mask\n",
    "\n",
    "def get_mask_subset_with_prob(mask, prob):\n",
    "    batch, seq_len, device = *mask.shape, mask.device\n",
    "    max_masked = math.ceil(prob * seq_len)      # num of mask of a single sequence in average\n",
    "    num_tokens = mask.sum(dim=-1, keepdim=True)     # num of pure tokens of each sequence except special tokens\n",
    "    mask_excess = torch.cat((torch.zeros(0), torch.arange(mask.size(-1)).repeat(mask.size(0)))).reshape(mask.size(0),mask.size(-1)).to(device)\n",
    "    mask_excess = (mask_excess >= (num_tokens * prob).ceil())        # only 15% of pure tokens can be masked\n",
    "    mask_excess = mask_excess[:, :max_masked]       # get difference between 15% of pure tokens and 15% of all tokens\n",
    "    rand = torch.rand((batch, seq_len), device=device).masked_fill(~mask, -1e9)     # rand (0-1) as prob, special token use -1e9\n",
    "    _, sampled_indices = rand.topk(max_masked, dim=-1)      # get index of topk prob to mask\n",
    "    sampled_indices = (sampled_indices + 1).masked_fill_(mask_excess, 0)        # delete difference of mask not pure\n",
    "    new_mask = torch.zeros((batch, seq_len + 1), device=device)     # get (batch, seq_len) shape zero matrix\n",
    "    new_mask.scatter_(-1, sampled_indices, 1)       # set masks in zero matrix as 1\n",
    "    return new_mask[:, 1:].bool()       # the final mask, True is mask\n",
    "\n",
    "def data_mask(\n",
    "    data,\n",
    "    mask_prob = MASK_PROB,\n",
    "    replace_prob = REPLACE_PROB,\n",
    "    num_tokens = None,\n",
    "    random_token_prob = RANDOM_TOKEN_PROB,\n",
    "    mask_token_id = MASK_TOKEN_ID,\n",
    "    pad_token_id = PAD_TOKEN_ID,\n",
    "    mask_ignore_token_ids = MASK_IGNORE_TOKEN_IDS\n",
    "):\n",
    "    mask_ignore_token_ids = set([*mask_ignore_token_ids, pad_token_id])\n",
    "    # do not mask [pad] tokens, or any other tokens in the tokens designated to be excluded ([cls], [sep])\n",
    "    # also do not include these special tokens in the tokens chosen at random\n",
    "    no_mask = mask_with_tokens(data, mask_ignore_token_ids)   # ignore_token as True, will not be masked later\n",
    "    mask = get_mask_subset_with_prob(~no_mask, mask_prob)      # get the True/False mask matrix\n",
    "    # get mask indices\n",
    "    ## mask_indices = torch.nonzero(mask, as_tuple=True)   # get the index of mask(nonzero value of mask matrix)\n",
    "    # mask input with mask tokens with probability of `replace_prob` (keep tokens the same with probability 1 - replace_prob)\n",
    "    masked_input = data.clone().detach()\n",
    "    # if random token probability > 0 for mlm\n",
    "    if random_token_prob > 0:\n",
    "        assert num_tokens is not None, 'num_tokens keyword must be supplied when instantiating MLM if using random token replacement'\n",
    "        random_token_prob = prob_mask_like(data, random_token_prob)       # get the mask matrix of random token replace\n",
    "        random_tokens = torch.randint(0, num_tokens, data.shape, device=data.device)     # generate random token matrix with the same shape as input\n",
    "        random_no_mask = mask_with_tokens(random_tokens, mask_ignore_token_ids)        # not masked matrix for the random token matrix\n",
    "        random_token_prob &= ~random_no_mask        # get the pure mask matrix of random token replace\n",
    "        random_indices = torch.nonzero(random_token_prob, as_tuple=True)        # index of random token replace\n",
    "        masked_data[random_indices] = random_tokens[random_indices]        # replace some tokens by random token\n",
    "    # [mask] input\n",
    "    replace_prob = prob_mask_like(data, replace_prob)     # get the mask matrix of token being masked\n",
    "    masked_input = masked_input.masked_fill(mask * replace_prob, mask_token_id)        # get the data has been masked by mask_token\n",
    "    # mask out any tokens to padding tokens that were not originally going to be masked\n",
    "    labels = data.masked_fill(~mask, pad_token_id)        # the label of masked tokens\n",
    "    return masked_input, labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zheng68K PBMC without g2v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pretrained_ckpt = \"ckpts/radium-ckpts_ckpts_fromGCP/radium-ckpts/scbert-baseline/ckpts/panglao_full_without_g2v/2022-May-11-17:37:29/panglao_full_without_g2v_epoch_6.pth\"\n",
    "data_path = \"/data/rna_rep_learning/scBERT/Zheng68K.h5ad\"\n",
    "g2v_file = \"/data/rna_rep_learning/scBERT/gene2vec_16906.npy\"\n",
    "POS_EMBED_USING=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#data\n",
    "adata = sc.read_h5ad(data_path)\n",
    "data = adata.X\n",
    "SEQ_LEN = data.shape[1] + 1 # num_genes + 1\n",
    "\n",
    "data_train, data_val = train_test_split(data, test_size=0.05, random_state=SEED)\n",
    "\n",
    "train_dataset = SCDataset(data_train)\n",
    "val_dataset = SCDataset(data_val)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# init model\n",
    "model = PerformerLM(\n",
    "    num_tokens = CLASS,\n",
    "    dim = 200,\n",
    "    depth = 6,\n",
    "    max_seq_len = SEQ_LEN,\n",
    "    heads = 10,\n",
    "    local_attn_heads = 0,\n",
    "    g2v_position_emb = POS_EMBED_USING,\n",
    "    #g2v_file = g2v_file\n",
    ")\n",
    "model.to(device);\n",
    "\n",
    "#load checkpoint\n",
    "checkpoint = torch.load(pretrained_ckpt, map_location=device)\n",
    "consume_prefix_in_state_dict_if_present(checkpoint['model_state_dict'], \"module.\")\n",
    "model.load_state_dict(checkpoint['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "predictions_list = [] #will be len masked genes\n",
    "truths_list = [] #will be len masked genes\n",
    "most_pop_list = [] #will be len ncells\n",
    "verbose=False\n",
    "with torch.no_grad():\n",
    "    for index, data_orig in enumerate(val_loader):\n",
    "        index += 1\n",
    "        data_orig = data_orig.to(device)\n",
    "        data, labels = data_mask(data_orig)\n",
    "        logits = model(data)\n",
    "        bucket, n = torch.unique(data_orig[data!=0], return_counts=True)\n",
    "        most_common_bin = bucket[torch.argmax(n)] #excluding the 0th bin\n",
    "        predictions = torch.argmax(logits[data==MASK_TOKEN_ID], axis=-1).cpu()\n",
    "        truths = data_orig[data==MASK_TOKEN_ID].cpu()\n",
    "        if verbose:\n",
    "            print(\"most popular bin: \" + str(most_common_bin))\n",
    "            print(\"frac genes in each bin: \" + str(n/torch.sum(n)))\n",
    "            print(\"masking accuracy in cell = {}\".format(torch.sum(predictions == truths) / len(predictions)))\n",
    "            print(\"\\n\")\n",
    "        predictions_list.append(predictions)\n",
    "        truths_list.append(truths)\n",
    "        most_pop_list.append(most_common_bin.item())\n",
    "        #if index==1000:\n",
    "            #break;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "preds_dict = {'predictions':predictions_list, 'truths':truths_list, 'most_pop':most_pop_list}\n",
    "fileObj = open('outputs/zheng68k_val_nog2v_maskingresults.pkl', 'wb')\n",
    "pickle.dump(preds_dict,fileObj)\n",
    "fileObj.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "masking accuracy: tensor(0.6806)\n"
     ]
    }
   ],
   "source": [
    "mask_acc = torch.sum(torch.cat(predictions_list) == torch.cat(truths_list)) / len(torch.cat(predictions_list))\n",
    "print(\"masking accuracy: \" + str(mask_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fraction of cells for which the most popular expression bucket was predicted\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "#for nog2v: fractions of cells for which the most popular expression bucket was predicted\n",
    "# with no g2v, each masked genes in the same cell has the same prediction, so can just look at 1 prediction per cell\n",
    "preds_per_cell = [preds[0] for preds in predictions_list]\n",
    "print(\"fraction of cells for which the most popular expression bucket was predicted\")\n",
    "print((np.sum(np.array(preds_per_cell) == np.array(most_pop_list))) / len(preds_per_cell))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#make a most_pop list that is the length of masked genes\n",
    "n_masked_per_cell = [len(i) for i in truths_list]\n",
    "most_pop_pergene = []\n",
    "for i in np.arange(len(most_pop_list)):\n",
    "    most_pop_pergene += list(np.repeat(most_pop_list[i], n_masked_per_cell[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frac of masked predictions that == most common bucket for that cell\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "#frac of masked predictions that == most common bucket for that cell\n",
    "print(\"frac of masked predictions that == most common bucket for that cell\")\n",
    "print(np.sum(most_pop_pergene==np.array(torch.cat(predictions_list)))/len(most_pop_pergene))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy that would be acheived by always predicting most popular bucket\n",
      "0.6806275249357683\n"
     ]
    }
   ],
   "source": [
    "#accuracy that would be acheived by always predicting most popular bucket\n",
    "print(\"accuracy that would be acheived by always predicting most popular bucket\")\n",
    "print(np.sum(most_pop_pergene==np.array(torch.cat(truths_list)))/len(most_pop_pergene))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zheng68K PBMC with g2v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pretrained_ckpt = \"ckpts/panglao_full_with_g2v/2022-May-11-17:38:47/panglao_full_with_g2v_epoch_17.pth\"\n",
    "data_path = \"/data/rna_rep_learning/scBERT/Zheng68K.h5ad\"\n",
    "g2v_file = \"/data/rna_rep_learning/scBERT/gene2vec_16906.npy\"\n",
    "POS_EMBED_USING=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#data\n",
    "adata = sc.read_h5ad(data_path)\n",
    "data = adata.X\n",
    "SEQ_LEN = data.shape[1] + 1 # num_genes + 1\n",
    "\n",
    "data_train, data_val = train_test_split(data, test_size=0.05, random_state=SEED)\n",
    "\n",
    "train_dataset = SCDataset(data_train)\n",
    "val_dataset = SCDataset(data_val)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# init model\n",
    "model = PerformerLM(\n",
    "    num_tokens = CLASS,\n",
    "    dim = 200,\n",
    "    depth = 6,\n",
    "    max_seq_len = SEQ_LEN,\n",
    "    heads = 10,\n",
    "    local_attn_heads = 0,\n",
    "    g2v_position_emb = POS_EMBED_USING,\n",
    "    g2v_file = g2v_file\n",
    ")\n",
    "model.to(device);\n",
    "\n",
    "#load checkpoint\n",
    "checkpoint = torch.load(pretrained_ckpt, map_location=device)\n",
    "consume_prefix_in_state_dict_if_present(checkpoint['model_state_dict'], \"module.\")\n",
    "model.load_state_dict(checkpoint['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "predictions_list = [] #will be len masked genes\n",
    "truths_list = [] #will be len masked genes\n",
    "most_pop_list = [] #will be len ncells\n",
    "verbose=False\n",
    "with torch.no_grad():\n",
    "    for index, data_orig in enumerate(val_loader):\n",
    "        index += 1\n",
    "        data_orig = data_orig.to(device)\n",
    "        data, labels = data_mask(data_orig)\n",
    "        logits = model(data)\n",
    "        bucket, n = torch.unique(data_orig[data!=0], return_counts=True)\n",
    "        most_common_bin = bucket[torch.argmax(n)] #excluding the 0th bin\n",
    "        predictions = torch.argmax(logits[data==MASK_TOKEN_ID], axis=-1).cpu()\n",
    "        truths = data_orig[data==MASK_TOKEN_ID].cpu()\n",
    "        if verbose:\n",
    "            print(\"most popular bin: \" + str(most_common_bin))\n",
    "            print(\"frac genes in each bin: \" + str(n/torch.sum(n)))\n",
    "            print(\"masking accuracy in cell = {}\".format(torch.sum(predictions == truths) / len(predictions)))\n",
    "            print(\"\\n\")\n",
    "        predictions_list.append(predictions)\n",
    "        truths_list.append(truths)\n",
    "        most_pop_list.append(most_common_bin.item())\n",
    "        #if index==1000:\n",
    "            #break;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "preds_dict = {'predictions':predictions_list, 'truths':truths_list, 'most_pop':most_pop_list}\n",
    "fileObj = open('outputs/zheng68k_val_g2v_maskingresults.pkl', 'wb')\n",
    "pickle.dump(preds_dict,fileObj)\n",
    "fileObj.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "masking accuracy: tensor(0.7882)\n"
     ]
    }
   ],
   "source": [
    "mask_acc = torch.sum(torch.cat(predictions_list) == torch.cat(truths_list)) / len(torch.cat(predictions_list))\n",
    "print(\"masking accuracy: \" + str(mask_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#for nog2v: fractions of cells for which the most popular expression bucket was predicted\n",
    "#N/A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#make a most_pop list that is the length of masked genes\n",
    "n_masked_per_cell = [len(i) for i in truths_list]\n",
    "most_pop_pergene = []\n",
    "for i in np.arange(len(most_pop_list)):\n",
    "    most_pop_pergene += list(np.repeat(most_pop_list[i], n_masked_per_cell[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frac of masked predictions that == most common bucket for that cell\n",
      "0.7929298177252457\n"
     ]
    }
   ],
   "source": [
    "#frac of masked predictions that == most common bucket for that cell\n",
    "print(\"frac of masked predictions that == most common bucket for that cell\")\n",
    "print(np.sum(most_pop_pergene==np.array(torch.cat(predictions_list)))/len(most_pop_pergene))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy that would be acheived by always predicting most popular bucket\n",
      "0.6799454474607092\n"
     ]
    }
   ],
   "source": [
    "#accuracy that would be acheived by always predicting most popular bucket\n",
    "print(\"accuracy that would be acheived by always predicting most popular bucket\")\n",
    "print(np.sum(most_pop_pergene==np.array(torch.cat(truths_list)))/len(most_pop_pergene))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Panglao data - no g2v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pretrained_ckpt = \"ckpts/radium-ckpts_ckpts_fromGCP/radium-ckpts/scbert-baseline/ckpts/panglao_full_without_g2v/2022-May-11-17:37:29/panglao_full_without_g2v_epoch_6.pth\"\n",
    "data_path = \"/data/rna_rep_learning/scBERT/panglao_human.h5ad\"\n",
    "g2v_file = \"/data/rna_rep_learning/scBERT/gene2vec_16906.npy\"\n",
    "POS_EMBED_USING=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/rpeyser/envs/rna-pretrain/lib/python3.9/site-packages/anndata/_core/anndata.py:1828: UserWarning: Observation names are not unique. To make them unique, call `.obs_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"obs\")\n"
     ]
    }
   ],
   "source": [
    "#data\n",
    "adata = sc.read_h5ad(data_path)\n",
    "data = adata.X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13.286486"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "SEQ_LEN = data.shape[1] + 1 # num_genes + 1\n",
    "data_train, data_val = train_test_split(data, test_size=0.05, random_state=SEED)\n",
    "\n",
    "train_dataset = SCDataset(data_train)\n",
    "val_dataset = SCDataset(data_val)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How many cells fall into each expression bucket?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2.17326020e+10, 5.15606541e+08, 3.44894659e+08, 1.65865366e+08,\n",
       "        9.72333360e+07, 6.82245970e+07, 2.10967310e+07, 4.84566700e+06,\n",
       "        7.73225000e+05, 1.87877000e+05, 7.57810000e+04, 4.42440000e+04,\n",
       "        1.72730000e+04, 3.00000000e+00]),\n",
       " array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14]),\n",
       " <BarContainer object of 14 artists>)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEDCAYAAAAlRP8qAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAOO0lEQVR4nO3df4zkdX3H8eerHNoiRrC3VXp3dYklGGv8gVdATQzRakEI16QYIVbB0lzaaMWGxIBNpKFJg2ljq8VKL3g9aSm2RdpeK/64qA02UcNyhYPjSrkohb1iWT0FLU3txXf/mO/V4djZmb2b3dn5+Hwkk5vvd773nXcuu8/97ne+M5eqQpI0/X5s0gNIksbDoEtSIwy6JDXCoEtSIwy6JDXCoEtSIyYa9CTbkzyW5L4Rtn1tkt1JDiW56IjHLk3yYHe7dOUmlqS1a9JH6DuAc0fc9mHgMuAv+1cmeS5wDXAWcCZwTZKTxzeiJE2HiQa9qu4ADvavS/LCJJ9JcleSLyV5UbftQ1W1B/jBEbv5RWBXVR2sqm8Duxj9h4QkNWPdpAdYxDbg16vqwSRnAX8CvG6J7TcAj/Qtz3frJOlHypoKepITgVcDf5Pk8OpnTm4iSZoeayro9E4BfaeqXr6Mv3MAOKdveSPwT+MbSZKmw6RfFH2KqnoC+HqSNwOk52VD/tpngTcmObl7MfSN3TpJ+pEy6csWbwG+DJyeZD7J5cBbgcuT3APsBbZ02/58knngzcCfJtkLUFUHgd8F7uxu13brJOlHSvz4XElqw5o65SJJOnoTe1F0/fr1NTs7O6mnl6SpdNddd32zqmYWe2xiQZ+dnWVubm5STy9JUynJvw96zFMuktQIgy5JjTDoktQIgy5JjTDoktQIgy5JjTDoktQIgy5JjTDoktSItfZ56COZvepTK7Lfh647f0X2K0mrwSN0SWqEQZekRhh0SWqEQZekRhh0SWqEQZekRhh0SWqEQZekRhh0SWqEQZekRhh0SWqEQZekRgwNepJNSb6Y5P4ke5Ncscg2SfLhJPuT7ElyxsqMK0kaZJRPWzwEXFlVu5M8G7grya6qur9vm/OA07rbWcBHuz8lSatk6BF6VT1aVbu7+98F9gEbjthsC3BT9XwFOCnJKWOfVpI00LLOoSeZBV4BfPWIhzYAj/Qtz/P06JNka5K5JHMLCwvLHFWStJSRg57kROCTwHuq6omjebKq2lZVm6tq88zMzNHsQpI0wEhBT3I8vZjfXFW3LbLJAWBT3/LGbp0kaZWMcpVLgI8B+6rqgwM22wm8vbva5Wzg8ap6dIxzSpKGGOUql9cAbwPuTXJ3t+59wM8AVNUNwO3Am4D9wJPAO8Y+qSRpSUODXlX/DGTINgW8c1xDSZKWz3eKSlIjDLokNcKgS1IjDLokNcKgS1IjDLokNcKgS1IjDLokNcKgS1IjDLokNcKgS1IjDLokNcKgS1IjDLokNcKgS1IjDLokNcKgS1IjDLokNcKgS1IjDLokNcKgS1IjDLokNcKgS1IjDLokNcKgS1IjDLokNcKgS1IjDLokNcKgS1IjDLokNcKgS1IjDLokNcKgS1IjDLokNcKgS1IjDLokNcKgS1IjDLokNcKgS1IjhgY9yfYkjyW5b8Dj5yR5PMnd3e394x9TkjTMuhG22QFcD9y0xDZfqqoLxjKRJOmoDD1Cr6o7gIOrMIsk6RiM6xz6q5Lck+TTSX5u0EZJtiaZSzK3sLAwpqeWJMF4gr4beEFVvQz4Y+DvBm1YVduqanNVbZ6ZmRnDU0uSDjvmoFfVE1X1ve7+7cDxSdYf82SSpGU55qAneX6SdPfP7Pb5rWPdryRpeYZe5ZLkFuAcYH2SeeAa4HiAqroBuAj4jSSHgP8GLq6qWrGJJUmLGhr0qrpkyOPX07usUZI0Qb5TVJIaYdAlqREGXZIaYdAlqREGXZIaYdAlqREGXZIaYdAlqREGXZIaYdAlqREGXZIaYdAlqREGXZIaYdAlqREGXZIaYdAlqREGXZIaYdAlqREGXZIaYdAlqREGXZIaYdAlqREGXZIaYdAlqREGXZIaYdAlqREGXZIaYdAlqREGXZIaYdAlqREGXZIaYdAlqREGXZIaYdAlqREGXZIaYdAlqREGXZIaYdAlqRFDg55ke5LHktw34PEk+XCS/Un2JDlj/GNKkoYZ5Qh9B3DuEo+fB5zW3bYCHz32sSRJyzU06FV1B3BwiU22ADdVz1eAk5KcMq4BJUmjGcc59A3AI33L8906SdIqWtUXRZNsTTKXZG5hYWE1n1qSmjeOoB8ANvUtb+zWPU1VbauqzVW1eWZmZgxPLUk6bBxB3wm8vbva5Wzg8ap6dAz7lSQtw7phGyS5BTgHWJ9kHrgGOB6gqm4AbgfeBOwHngTesVLDSpIGGxr0qrpkyOMFvHNsE0mSjorvFJWkRhh0SWqEQZekRhh0SWqEQZekRhh0SWqEQZekRhh0SWqEQZekRhh0SWqEQZekRhh0SWqEQZekRhh0SWqEQZekRhh0SWqEQZekRhh0SWqEQZekRhh0SWqEQZekRhh0SWqEQZekRhh0SWqEQZekRhh0SWqEQZekRhh0SWqEQZekRhh0SWqEQZekRhh0SWqEQZekRhh0SWqEQZekRhh0SWqEQZekRhh0SWqEQZekRowU9CTnJnkgyf4kVy3y+GVJFpLc3d1+bfyjSpKWsm7YBkmOAz4CvAGYB+5MsrOq7j9i07+qqnetwIySpBGMcoR+JrC/qr5WVd8HPgFsWdmxJEnLNUrQNwCP9C3Pd+uO9MtJ9iS5NcmmxXaUZGuSuSRzCwsLRzGuJGmQcb0o+g/AbFW9FNgFfHyxjapqW1VtrqrNMzMzY3pqSRKMFvQDQP8R98Zu3f+rqm9V1f90izcCrxzPeJKkUY0S9DuB05KcmuQZwMXAzv4NkpzSt3ghsG98I0qSRjH0KpeqOpTkXcBngeOA7VW1N8m1wFxV7QTeneRC4BBwELhsBWeWJC1iaNABqup24PYj1r2/7/7VwNXjHU2StBy+U1SSGmHQJakRBl2SGmHQJakRBl2SGmHQJakRBl2SGmHQJakRBl2SGmHQJakRBl2SGmHQJakRBl2SGmHQJakRBl2SGmHQJakRBl2SGmHQJakRBl2SGmHQJakRBl2SGmHQJakRBl2SGmHQJakRBl2SGmHQJakRBl2SGmHQJakRBl2SGmHQJakRBl2SGmHQJakRBl2SGmHQJakRBl2SGmHQJakRBl2SGrFu0gOsJbNXfWpF9vvQdeevyH4lqZ9H6JLUiJGO0JOcC3wIOA64saquO+LxZwI3Aa8EvgW8paoeGu+o08sjf0mrYWjQkxwHfAR4AzAP3JlkZ1Xd37fZ5cC3q+pnk1wMfAB4y0oMrB9aiR8U/pCQptcoR+hnAvur6msAST4BbAH6g74F+J3u/q3A9UlSVTXGWbUKVuq3iZXiDyDph0YJ+gbgkb7leeCsQdtU1aEkjwM/CXyzf6MkW4Gt3eL3kjxwNEMD64/c9xo3TfNO06zkA1M17zTNCtM17zTNCsc27wsGPbCqV7lU1TZg27HuJ8lcVW0ew0irYprmnaZZYbrmnaZZYbrmnaZZYeXmHeUqlwPApr7ljd26RbdJsg54Dr0XRyVJq2SUoN8JnJbk1CTPAC4Gdh6xzU7g0u7+RcAXPH8uSatr6CmX7pz4u4DP0rtscXtV7U1yLTBXVTuBjwF/nmQ/cJBe9FfSMZ+2WWXTNO80zQrTNe80zQrTNe80zQorNG88kJakNvhOUUlqhEGXpEZMXdCTnJvkgST7k1w16XkGSbIpyReT3J9kb5IrJj3TKJIcl+RfkvzjpGdZSpKTktya5F+T7EvyqknPtJQkv9V9HdyX5JYkPz7pmfol2Z7ksST39a17bpJdSR7s/jx5kjMeNmDW3+++FvYk+dskJ01wxKdYbN6+x65MUknWj+O5pirofR9DcB7wYuCSJC+e7FQDHQKurKoXA2cD71zDs/a7Atg36SFG8CHgM1X1IuBlrOGZk2wA3g1srqqX0Lu4YKUvHFiuHcC5R6y7Cvh8VZ0GfL5bXgt28PRZdwEvqaqXAv8GXL3aQy1hB0+flySbgDcCD4/riaYq6PR9DEFVfR84/DEEa05VPVpVu7v736UXnA2TnWppSTYC5wM3TnqWpSR5DvBaeldXUVXfr6rvTHSo4dYBP9G9T+ME4D8mPM9TVNUd9K5Q67cF+Hh3/+PAL63mTIMsNmtVfa6qDnWLX6H3fpk1YcC/LcAfAu8FxnZlyrQFfbGPIVjTkQRIMgu8AvjqhEcZ5o/ofYH9YMJzDHMqsAD8WXd66MYkz5r0UINU1QHgD+gdiT0KPF5Vn5vsVCN5XlU92t3/BvC8SQ6zDL8KfHrSQywlyRbgQFXdM879TlvQp06SE4FPAu+pqicmPc8gSS4AHququyY9ywjWAWcAH62qVwD/xdo5HfA03bnnLfR+EP008KwkvzLZqZane6Pgmr/GOclv0zvdefOkZxkkyQnA+4D3j3vf0xb0UT6GYM1Icjy9mN9cVbdNep4hXgNcmOQheqeyXpfkLyY70kDzwHxVHf6N51Z6gV+rfgH4elUtVNX/ArcBr57wTKP4zySnAHR/PjbheZaU5DLgAuCta/yd6i+k98P9nu77bSOwO8nzj3XH0xb0UT6GYE1IEnrnePdV1QcnPc8wVXV1VW2sqll6/65fqKo1eRRZVd8AHklyerfq9Tz145zXmoeBs5Oc0H1dvJ41/CJun/6P9LgU+PsJzrKk7j/heS9wYVU9Oel5llJV91bVT1XVbPf9Ng+c0X1dH5OpCnr3osfhjyHYB/x1Ve2d7FQDvQZ4G70j3bu725smPVRDfhO4Ocke4OXA7012nMG63yRuBXYD99L7vltTb1VPcgvwZeD0JPNJLgeuA96Q5EF6v2Vct9Q+VsuAWa8Hng3s6r7XbpjokH0GzLsyz7W2fzORJI1qqo7QJUmDGXRJaoRBl6RGGHRJaoRBl6RGGHRJaoRBl6RG/B/Ham6F2c8WGgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(np.array(adata.X.todense()).reshape(-1), bins=[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9.46893796e-01, 2.24650797e-02, 1.50271290e-02, 7.22678702e-03,\n",
       "       4.23647581e-03, 2.97255928e-03, 9.19188770e-04, 2.11126676e-04,\n",
       "       3.36895672e-05, 8.18583830e-06, 3.30179326e-06, 1.92771989e-06,\n",
       "       7.52588049e-07, 1.30710597e-10])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#percentages in each bin\n",
    "[2.17326020e+10, 5.15606541e+08, 3.44894659e+08, 1.65865366e+08,\n",
    "        9.72333360e+07, 6.82245970e+07, 2.10967310e+07, 4.84566700e+06,\n",
    "        7.73225000e+05, 1.87877000e+05, 7.57810000e+04, 4.42440000e+04,\n",
    "        1.72730000e+04, 3.00000000e+00]/np.sum([2.17326020e+10, 5.15606541e+08, 3.44894659e+08, 1.65865366e+08,\n",
    "        9.72333360e+07, 6.82245970e+07, 2.10967310e+07, 4.84566700e+06,\n",
    "        7.73225000e+05, 1.87877000e+05, 7.57810000e+04, 4.42440000e+04,\n",
    "        1.72730000e+04, 3.00000000e+00])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0041507323634095965"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#percent of genes in final bin (5+)\n",
    "np.sum([2.97255928e-03, 9.19188770e-04, 2.11126676e-04,\n",
    "       3.36895672e-05, 8.18583830e-06, 3.30179326e-06, 1.92771989e-06,\n",
    "       7.52588049e-07, 1.30710597e-10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# init model\n",
    "model = PerformerLM(\n",
    "    num_tokens = CLASS,\n",
    "    dim = 200,\n",
    "    depth = 6,\n",
    "    max_seq_len = SEQ_LEN,\n",
    "    heads = 10,\n",
    "    local_attn_heads = 0,\n",
    "    g2v_position_emb = POS_EMBED_USING,\n",
    "    #g2v_file = g2v_file\n",
    ")\n",
    "model.to(device);\n",
    "\n",
    "#load checkpoint\n",
    "checkpoint = torch.load(pretrained_ckpt, map_location=device)\n",
    "consume_prefix_in_state_dict_if_present(checkpoint['model_state_dict'], \"module.\")\n",
    "model.load_state_dict(checkpoint['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "predictions_list = [] #will be len masked genes\n",
    "truths_list = [] #will be len masked genes\n",
    "most_pop_list = [] #will be len ncells\n",
    "verbose=False\n",
    "with torch.no_grad():\n",
    "    for index, data_orig in enumerate(val_loader):\n",
    "        index += 1\n",
    "        data_orig = data_orig.to(device)\n",
    "        data, labels = data_mask(data_orig)\n",
    "        logits = model(data)\n",
    "        bucket, n = torch.unique(data_orig[data!=0], return_counts=True)\n",
    "        most_common_bin = bucket[torch.argmax(n)] #excluding the 0th bin\n",
    "        predictions = torch.argmax(logits[data==MASK_TOKEN_ID], axis=-1).cpu()\n",
    "        truths = data_orig[data==MASK_TOKEN_ID].cpu()\n",
    "        if verbose:\n",
    "            print(\"most popular bin: \" + str(most_common_bin))\n",
    "            print(\"frac genes in each bin: \" + str(n/torch.sum(n)))\n",
    "            print(\"masking accuracy in cell = {}\".format(torch.sum(predictions == truths) / len(predictions)))\n",
    "            print(\"\\n\")\n",
    "        predictions_list.append(predictions)\n",
    "        truths_list.append(truths)\n",
    "        most_pop_list.append(most_common_bin.item())\n",
    "        #if index==1000:\n",
    "            #break;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "preds_dict = {'predictions':predictions_list, 'truths':truths_list, 'most_pop':most_pop_list}\n",
    "fileObj = open('outputs/panglao_val_nog2v_maskingresults.pkl', 'wb')\n",
    "pickle.dump(preds_dict,fileObj)\n",
    "fileObj.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "masking accuracy: tensor(0.7231)\n"
     ]
    }
   ],
   "source": [
    "mask_acc = torch.sum(torch.cat(predictions_list) == torch.cat(truths_list)) / len(torch.cat(predictions_list))\n",
    "print(\"masking accuracy: \" + str(mask_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fraction of cells for which the most popular expression bucket was predicted\n",
      "0.9985562757807896\n"
     ]
    }
   ],
   "source": [
    "#for nog2v: fractions of cells for which the most popular expression bucket was predicted\n",
    "# with no g2v, each masked genes in the same cell has the same prediction, so can just look at 1 prediction per cell\n",
    "preds_per_cell = [preds[0] for preds in predictions_list]\n",
    "print(\"fraction of cells for which the most popular expression bucket was predicted\")\n",
    "print((np.sum(np.array(preds_per_cell) == np.array(most_pop_list))) / len(preds_per_cell))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#make a most_pop list that is the length of masked genes\n",
    "n_masked_per_cell = [len(i) for i in truths_list]\n",
    "most_pop_pergene = []\n",
    "for i in np.arange(len(most_pop_list)):\n",
    "    most_pop_pergene += list(np.repeat(most_pop_list[i], n_masked_per_cell[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frac of masked predictions that == most common bucket for that cell\n",
      "0.9990534044903671\n"
     ]
    }
   ],
   "source": [
    "#frac of masked predictions that == most common bucket for that cell\n",
    "print(\"frac of masked predictions that == most common bucket for that cell\")\n",
    "print(np.sum(most_pop_pergene==np.array(torch.cat(predictions_list)))/len(most_pop_pergene))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy that would be acheived by always predicting most popular bucket\n",
      "0.7231690398804856\n"
     ]
    }
   ],
   "source": [
    "#accuracy that would be acheived by always predicting most popular bucket\n",
    "print(\"accuracy that would be acheived by always predicting most popular bucket\")\n",
    "print(np.sum(most_pop_pergene==np.array(torch.cat(truths_list)))/len(most_pop_pergene))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Panglao data - with g2v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pretrained_ckpt = \"ckpts/panglao_full_with_g2v/2022-May-11-17:38:47/panglao_full_with_g2v_epoch_17.pth\"\n",
    "data_path = \"/data/rna_rep_learning/scBERT/panglao_human.h5ad\"\n",
    "g2v_file = \"/data/rna_rep_learning/scBERT/gene2vec_16906.npy\"\n",
    "POS_EMBED_USING=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/rpeyser/envs/rna-pretrain/lib/python3.9/site-packages/anndata/_core/anndata.py:1828: UserWarning: Observation names are not unique. To make them unique, call `.obs_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"obs\")\n"
     ]
    }
   ],
   "source": [
    "#data\n",
    "adata = sc.read_h5ad(data_path)\n",
    "data = adata.X\n",
    "SEQ_LEN = data.shape[1] + 1 # num_genes + 1\n",
    "\n",
    "data_train, data_val = train_test_split(data, test_size=0.05, random_state=SEED)\n",
    "\n",
    "train_dataset = SCDataset(data_train)\n",
    "val_dataset = SCDataset(data_val)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# init model\n",
    "model = PerformerLM(\n",
    "    num_tokens = CLASS,\n",
    "    dim = 200,\n",
    "    depth = 6,\n",
    "    max_seq_len = SEQ_LEN,\n",
    "    heads = 10,\n",
    "    local_attn_heads = 0,\n",
    "    g2v_position_emb = POS_EMBED_USING,\n",
    "    g2v_file = g2v_file\n",
    ")\n",
    "model.to(device);\n",
    "\n",
    "#load checkpoint\n",
    "checkpoint = torch.load(pretrained_ckpt, map_location=device)\n",
    "consume_prefix_in_state_dict_if_present(checkpoint['model_state_dict'], \"module.\")\n",
    "model.load_state_dict(checkpoint['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "predictions_list = [] #will be len masked genes\n",
    "truths_list = [] #will be len masked genes\n",
    "most_pop_list = [] #will be len ncells\n",
    "verbose=False\n",
    "with torch.no_grad():\n",
    "    for index, data_orig in enumerate(val_loader):\n",
    "        index += 1\n",
    "        data_orig = data_orig.to(device)\n",
    "        data, labels = data_mask(data_orig)\n",
    "        logits = model(data)\n",
    "        bucket, n = torch.unique(data_orig[data!=0], return_counts=True)\n",
    "        most_common_bin = bucket[torch.argmax(n)] #excluding the 0th bin\n",
    "        predictions = torch.argmax(logits[data==MASK_TOKEN_ID], axis=-1).cpu()\n",
    "        truths = data_orig[data==MASK_TOKEN_ID].cpu()\n",
    "        if verbose:\n",
    "            print(\"most popular bin: \" + str(most_common_bin))\n",
    "            print(\"frac genes in each bin: \" + str(n/torch.sum(n)))\n",
    "            print(\"masking accuracy in cell = {}\".format(torch.sum(predictions == truths) / len(predictions)))\n",
    "            print(\"\\n\")\n",
    "        predictions_list.append(predictions)\n",
    "        truths_list.append(truths)\n",
    "        most_pop_list.append(most_common_bin.item())\n",
    "        #if index==1000:\n",
    "            #break;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "preds_dict = {'predictions':predictions_list, 'truths':truths_list, 'most_pop':most_pop_list}\n",
    "fileObj = open('outputs/panglao_val_g2v_maskingresults.pkl', 'wb')\n",
    "pickle.dump(preds_dict,fileObj)\n",
    "fileObj.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "masking accuracy: tensor(0.7845)\n"
     ]
    }
   ],
   "source": [
    "mask_acc = torch.sum(torch.cat(predictions_list) == torch.cat(truths_list)) / len(torch.cat(predictions_list))\n",
    "print(\"masking accuracy: \" + str(mask_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for nog2v: fractions of cells for which the most popular expression bucket was predicted\n",
    "#N/A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#make a most_pop list that is the length of masked genes\n",
    "n_masked_per_cell = [len(i) for i in truths_list]\n",
    "most_pop_pergene = []\n",
    "for i in np.arange(len(most_pop_list)):\n",
    "    most_pop_pergene += list(np.repeat(most_pop_list[i], n_masked_per_cell[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frac of masked predictions that == most common bucket for that cell\n",
      "0.8377435863633439\n"
     ]
    }
   ],
   "source": [
    "#frac of masked predictions that == most common bucket for that cell\n",
    "print(\"frac of masked predictions that == most common bucket for that cell\")\n",
    "print(np.sum(most_pop_pergene==np.array(torch.cat(predictions_list)))/len(most_pop_pergene))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy that would be acheived by always predicting most popular bucket\n",
      "0.7234092876125383\n"
     ]
    }
   ],
   "source": [
    "#accuracy that would be acheived by always predicting most popular bucket\n",
    "print(\"accuracy that would be acheived by always predicting most popular bucket\")\n",
    "print(np.sum(most_pop_pergene==np.array(torch.cat(truths_list)))/len(most_pop_pergene))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rna-pretrain",
   "language": "python",
   "name": "rna-pretrain"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "ea531a0049080d5658e3e61cf7db54ce403b028279b105adc411fb7eae04af57"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
